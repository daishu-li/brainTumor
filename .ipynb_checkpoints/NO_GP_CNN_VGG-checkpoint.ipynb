{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import math\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy\n",
    "import gc\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'E:\\\\GPImage\\\\HandleImage\\\\Train\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     4
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "# 读取图片， 并将data和label分别写入\n",
    "def read_img(path):\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    fileList = os.listdir(path)\n",
    "    totalNum = len(fileList)\n",
    "    \n",
    "    for i in range(0, totalNum):\n",
    "        iPath = path + str(fileList[i])\n",
    "        #  添加 文件标签\n",
    "        # 获取文件名\n",
    "        y = fileList[i]\n",
    "        #     print(y)\n",
    "    \n",
    "        # 去除文件后缀\n",
    "        y = os.path.splitext(y)\n",
    "        #     print(y)\n",
    "        y_ = y[0]\n",
    "        #     print(y_)\n",
    "    \n",
    "        # 去除文件中的数字，获取文件标签\n",
    "        # 设置标签 1为eye 2为back 3为face 4为left 5为up         \n",
    "        y_ = \"\".join(filter(str.isalpha, y_))\n",
    "        # print(type(y_))\n",
    "        if(y_ == 'eye'):\n",
    "            y_label = 1.0\n",
    "        elif(y_ == 'back'):\n",
    "            y_label = 2.0\n",
    "        elif(y_ == 'face'):\n",
    "            y_label = 3.0\n",
    "        elif(y_ == 'left'):\n",
    "            y_label = 4.0\n",
    "        else:\n",
    "            y_label = 5.0\n",
    "        \n",
    "        # 添加标签  \n",
    "        labels.append(y_label)\n",
    "    \n",
    "        #   添加文件图片数据 \n",
    "        src = cv.imread(iPath)\n",
    "        image = cv.cvtColor(src, cv.COLOR_BGR2GRAY)\n",
    "        imgs.append(image)\n",
    "    return np.asarray(imgs, np.float32), np.asarray(labels, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0,
     6,
     8,
     10,
     13
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_op(input_op, name, kh, kw, n_out, dh, dw, p):\n",
    "    print(\"卷积层\")\n",
    "    print(\"input_op的类型： \" + str(type(input_op)))\n",
    "    n_in = tf.Tensor.get_shape(input_op)[-1]\n",
    "    #input_op.size()[-1]\n",
    "    \n",
    "#     n_in = input_op.get_shape()[-1].value\n",
    "    print(\"n_in的大小 ： \" + str(n_in))\n",
    "#     print(\"P的类型\" + str(type(p)))\n",
    "    \n",
    "    with tf.name_scope(name) as scope:\n",
    "        kernel = tf.get_variable(scope+\"w\", shape=[kh,kw,n_in,n_out], dtype=tf.float32,\n",
    "                                 initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "#         print(\"kernel \" + str(type(kernel)))\n",
    "        conv = tf.nn.conv2d(input_op, kernel, (1, dh, dw, 1), padding='SAME')\n",
    "        bias_init_val = tf.constant(0.0, shape=[n_out], dtype=tf.float32)\n",
    "        biases = tf.Variable(bias_init_val, trainable=True, name='b')\n",
    "        z = tf.nn.bias_add(conv,biases)\n",
    "        activation = tf.nn.relu(z, name=scope)\n",
    "        p += [kernel, biases]\n",
    "        return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fc_op(input_op, name, n_out, p):\n",
    "    n_in = tf.Tensor.get_shape(input_op)[-1]\n",
    "    \n",
    "    with tf.name_scope(name) as scope:\n",
    "        kernel = tf.get_variable(scope+\"w\", shape=[n_in, n_out], dtype=tf.float32,\n",
    "                                 initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.Variable(tf.constant(0.1, shape=[n_out], dtype=tf.float32), name='b')\n",
    "        activation = tf.nn.relu_layer(input_op, kernel, biases, name= scope)\n",
    "        p += [kernel, biases]\n",
    "        return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mpool_op(input_op, name, kh, kw, dh, dw):\n",
    "    print(\"池化层\")\n",
    "    return tf.nn.max_pool(input_op,\n",
    "                          ksize=[1, kh, kw, 1],\n",
    "                          strides=[1, dh, dw, 1],\n",
    "                          padding='SAME',\n",
    "                          name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     11,
     22,
     25,
     34,
     37,
     40,
     50,
     53,
     56,
     70,
     73,
     76
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference_op(input_op,keep_prob):\n",
    "    \n",
    "    p = []\n",
    "    print(\"p 的类型\" + str(type(p)))\n",
    "    \n",
    "    # 第一段卷积的第一个卷积层 卷积核3*3，共64个卷积核（输出通道数），步长1*1\n",
    "    # input_op：256*256*1 输出尺寸256*256*64\n",
    "    conv1_1 = conv_op(input_op, name=\"conv1_1\", kh=3, kw=3, n_out=64, dh=1,\n",
    "                      dw=1, p=p)\n",
    "    print(\"conv1_1 \" + str(conv1_1))\n",
    "    # 第一段卷积的第2个卷积层 卷积核3*3，共64个卷积核（输出通道数），步长1*1\n",
    "    # input_op：256*256*64 输出尺寸256*256*64\n",
    "    conv1_2 = conv_op(conv1_1, name=\"conv1_2\", kh=3, kw=3, n_out=64, dh=1,\n",
    "                      dw=1, p=p)\n",
    "    print(\"conv1_2 \" + str(conv1_2))\n",
    "    # 第一段卷积的pooling层，核2*2，步长2*2\n",
    "    # input_op：256*256*64 输出尺寸128*128*64\n",
    "    pool1 = mpool_op(conv1_2, name=\"pool1\", kh=2, kw=2, dh=2, dw=2)\n",
    "    print(\"pool1 \" + str(pool1))\n",
    "    \n",
    "    # 下面是第2段卷积，包含2个卷积层和一个pooling层\n",
    "    # 第2段卷积的第一个卷积层 卷积核3*3，共128个卷积核（输出通道数），步长1*1\n",
    "    # input_op：128*128*64 输出尺寸128*128*128\n",
    "    conv2_1 = conv_op(pool1, name=\"conv2_1\", kh=3, kw=3, n_out=128, dh=1,\n",
    "                      dw=1, p=p)\n",
    "    print(\"conv2_1 \" + str(conv2_1))\n",
    "    # input_op：128*128*128 输出尺寸128*128*128\n",
    "    conv2_2 = conv_op(conv2_1, name=\"conv2_2\", kh=3, kw=3, n_out=128, dh=1,\n",
    "                      dw=1, p=p)\n",
    "    print(\"conv2_2 \" + str(conv2_2))\n",
    "    # input_op：128*128*128 输出尺寸64*64*128\n",
    "    pool2 = mpool_op(conv2_2, name=\"pool2\", kh=2, kw=2, dh=2, dw=2)\n",
    "    print(\"pool2 \" + str(pool2))\n",
    "    \n",
    "    # 下面是第3段卷积，包含3个卷积层和一个pooling层\n",
    "    # 第3段卷积的第一个卷积层 卷积核3*3，共256个卷积核（输出通道数），步长1*1\n",
    "    # input_op：64*64*128 输出尺寸64*64*256\n",
    "    conv3_1 = conv_op(pool2, name=\"conv3_1\", kh=3, kw=3, n_out=256, dh=1,\n",
    "                      dw=1, p=p)\n",
    "    print(\"conv3_1 \" + str(conv3_1))\n",
    "    # input_op：64*64*256 输出尺寸64*64*256\n",
    "    conv3_2 = conv_op(conv3_1, name=\"conv3_2\", kh=3, kw=3, n_out=256, dh=1,\n",
    "                      dw=1, p=p)\n",
    "    print(\"conv3_2 \" + str(conv3_2))\n",
    "    # input_op：64*64*256 输出尺寸64*64*256\n",
    "    conv3_3 = conv_op(conv3_2, name=\"conv3_3\", kh=3, kw=3, n_out=256, dh=1,\n",
    "                      dw=1, p=p)\n",
    "    print(\"conv3_3 \" + str(conv3_3))\n",
    "    # input_op：64*64*256 输出尺寸 32*32*256\n",
    "    pool3 = mpool_op(conv3_3, name=\"pool3\", kh=2, kw=2, dh=2, dw=2)\n",
    "    print(\"pool3 \" + str(pool3))\n",
    "    \n",
    "    \n",
    "    # 下面是第4段卷积，包含3个卷积层和一个pooling层\n",
    "    # 第3段卷积的第一个卷积层 卷积核3*3，共512个卷积核（输出通道数），步长1*1\n",
    "    # input_op：32*32*256 输出尺寸32*32*512\n",
    "    conv4_1 = conv_op(pool3, name=\"conv4_1\", kh=3, kw=3, n_out=512, dh=1,\n",
    "                      dw=1, p=p)\n",
    "    print(\"conv4_1 \" + str(conv4_1))\n",
    "    # input_op：32*32*512 输出尺寸 32*32*512\n",
    "    conv4_2 = conv_op(conv4_1, name=\"conv4_2\", kh=3, kw=3, n_out=512, dh=1,\n",
    "                      dw=1, p=p)\n",
    "    print(\"conv4_2 \" + str(conv4_2))\n",
    "    # input_op：32*32*512 输出尺寸 32*32*512\n",
    "    conv4_3 = conv_op(conv4_2, name=\"conv4_3\", kh=3, kw=3, n_out=512, dh=1,\n",
    "                      dw=1, p=p)\n",
    "    print(\"conv4_3 \" + str(conv4_3))\n",
    "    # input_op：32*32*512 输出尺寸 16*16*512\n",
    "    pool4 = mpool_op(conv4_3, name=\"pool4\", kh=2, kw=2, dh=2, dw=2)\n",
    "    print(\"pool4 \" + str(pool4))\n",
    "    \n",
    "    # 前面4段卷积发现，VGG16每段卷积都是把图像面积变为1/4，但是通道数翻倍\n",
    "    # 因此图像tensor的总尺寸缩小一半\n",
    "\n",
    "    # 下面是第5段卷积，包含3个卷积层和一个pooling层\n",
    "    # 第3段卷积的第一个卷积层 卷积核3*3，共512个卷积核（输出通道数），步长1*1\n",
    "    # input_op：16*16*512 输出尺寸 16*16*512\n",
    "    conv5_1 = conv_op(pool4, name=\"conv5_1\", kh=3, kw=3, n_out=512, dh=1,\n",
    "                      dw=1, p=p)\n",
    "    print(\"conv5_1 \" + str(conv5_1))\n",
    "    # input_op：16*16*512 输出尺寸 16*16*512\n",
    "    conv5_2 = conv_op(conv5_1, name=\"conv5_2\", kh=3, kw=3, n_out=512, dh=1,\n",
    "                      dw=1, p=p)\n",
    "    # input_op：16*16*512 输出尺寸 16*16*512\n",
    "    print(\"conv5_2 \" + str(conv5_2))\n",
    "    conv5_3 = conv_op(conv5_2, name=\"conv5_3\", kh=3, kw=3, n_out=512, dh=1,\n",
    "                      dw=1, p=p)\n",
    "    print(\"conv5_3 \" + str(conv5_3))\n",
    "    # input_op：16*16*512 输出尺寸 8*8*512\n",
    "    pool5 = mpool_op(conv5_3, name=\"pool5\", kh=2, kw=2, dh=2, dw=2)\n",
    "    print(\"pool5 \" + str(pool5))\n",
    "    \n",
    "    # 将第五段卷积网络的结果扁平化\n",
    "    # reshape将每张图片变为 8*8*512 = 32768的一维向量\n",
    "    shp = pool5.get_shape()\n",
    "    \n",
    "    print(\"shp的shape: \" + str(shp))\n",
    "    \n",
    "    flattened_shape = shp[1].value * shp[2].value * shp[3].value\n",
    "    # tf.reshape(tensor, shape, name=None) 将tensor变换为参数shape的形式。\n",
    "    resh1 = tf.reshape(pool5, [-1, flattened_shape], name=\"resh1\")\n",
    "\n",
    "    print(\"resh1的类型\" + str(type(resh1)))\n",
    "    print(resh1)\n",
    "    \n",
    "    # 第一个全连接层，是一个隐藏节点数为4096的全连接层\n",
    "    # 后面接一个dropout层，训练时保留率为0.5，预测时为1.0\n",
    "    fc6 = fc_op(resh1, name=\"fc6\", n_out=4096, p=p)\n",
    "    print(\"fc6 的shape: \" + str(fc6))\n",
    "    print(\"keep_prob 的shape： \" + str(keep_prob))\n",
    "    fc6_drop = tf.nn.dropout(fc6, keep_prob, name=\"fc6_drop\")\n",
    " \n",
    "    \n",
    "    # 第2个全连接层，是一个隐藏节点数为4096的全连接层\n",
    "    # 后面接一个dropout层，训练时保留率为0.5，预测时为1.0\n",
    "    fc7 = fc_op(fc6_drop, name=\"fc7\", n_out=4096, p=p)\n",
    "    fc7_drop = tf.nn.dropout(fc7, keep_prob, name=\"fc7_drop\")\n",
    "\n",
    "    \n",
    "    # 最后是一个1000个输出节点的全连接层\n",
    "    # 利用softmax输出分类概率\n",
    "    # argmax输出概率最大的类别\n",
    "    fc8 = fc_op(fc7_drop, name=\"fc8\", n_out=1000, p=p)\n",
    "    softmax = tf.nn.softmax(fc8)\n",
    "    predictions = tf.argmax(softmax, 1)\n",
    "    return predictions, softmax, fc8, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_tensorflow_run(session, target, feed, info_string): # 与AlexNet非常相似，session参数一点点区别\n",
    "    # num_steps_burn_in预热轮数，前几轮有显存加载，可以跳过时间评测\n",
    "    # 只计算10轮迭代后的计算时间\n",
    "    num_steps_burn_in = 10\n",
    "    # 总时间\n",
    "    total_duration = 0.0\n",
    "    # 总时间的平方\n",
    "    total_duration_squared = 0.0\n",
    "    # 进行num_batches + num_steps_burn_in次迭代计算\n",
    "    for i in range(num_batches + num_steps_burn_in):\n",
    "        # 使用time.time()记录时间\n",
    "        start_time = time.time()\n",
    "        # 每次迭代通过session.run执行\n",
    "        _ = session.run(target, feed_dict=feed) # 引入feed_dict方便后面传入keep_prob来控制Dropout层的保留比率\n",
    "        duration = time.time() - start_time\n",
    "        print(str(type(duration)) + \"   time:  \" + str(duration))\n",
    "        # 在预热之后\n",
    "        if i >= num_steps_burn_in:\n",
    "            # 每10轮迭代显示当前迭代所需时间\n",
    "            if not i % 10:\n",
    "                print (str(datetime.now()) + \": step \" +\n",
    "                       str(i - num_steps_burn_in) + \n",
    "                       \", duration = \" + str(duration))\n",
    "            total_duration += duration\n",
    "            total_duration_squared += duration * duration\n",
    "    # 计算每轮迭代的平均耗时和标准差\n",
    "    mn = total_duration / num_batches\n",
    "    vr = total_duration_squared / num_batches - mn * mn\n",
    "    sd = math.sqrt(vr)\n",
    "    print (str(datetime.now()) + \": \" +\n",
    "           str(info_string) + \"across \" + \n",
    "           str(num_batches) + \" steps, \" +  \n",
    "           str(mn) + \" +/- \" + str(sd) + \"sec / batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_benchmark():\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "        \n",
    "        image, label = read_img(path)\n",
    "        print(image.shape)\n",
    "        images_ = numpy.reshape(image, [50, 256, 256, 1])\n",
    "        print(images_.shape)\n",
    "#         -----------------------------------------------------------\n",
    "        print(str(type(images_)))# numpy\n",
    "        print(\"***********************************************************\")    \n",
    "        in_put = Variable(torch.from_numpy(images_))\n",
    "        print(\"run_benchmark中    image  \" +str(type(in_put)))\n",
    "        print(\"***********************************************************\")\n",
    "#         ----------------------------------------------------------- \n",
    "        \n",
    "        print(\"元素的类型： \" + str(type(label[-1])))\n",
    "        \n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "#         keep_prob = tf.convert_to_tensor(label)\n",
    "#         keep_prob = Variable(torch.from_numpy(label))\n",
    "#         print(\"标签的类型 ：\" + str(type(keep_prob)))\n",
    "        # keep_prob = tf.placeholder(tf.float32)\n",
    "        \n",
    "        predictions, softmax, fc8, p = inference_op(in_put, keep_prob)  # 构建网络结构获得参数列表\n",
    "\n",
    "        print(\"...................................................\")\n",
    "        print(\"变量所占内存大小 ： \" )\n",
    "        print(sys.getsizeof(predictions))\n",
    "        print(sys.getsizeof(softmax))\n",
    "        print(sys.getsizeof(fc8))\n",
    "        print(sys.getsizeof(p))\n",
    "        print(\"...................................................\")\n",
    "        # 通过tf.session创建新的session，并通过global_variable初始化所有参数\n",
    "        # 并通过run运行该session 只有运行run并feed数据运算才真正执行\n",
    "        init = tf.global_variables_initializer()  # 初始化全局参数\n",
    "        sess = tf.Session()  # 创建session\n",
    "        sess.run(init)\n",
    "\n",
    "        time_tensorflow_run(sess, predictions, {keep_prob: 1.0}, \"Forward\")  # 预测时节点保留率\n",
    "\n",
    "        print(\"函数已大致运行完成///////////////////////////////////\")\n",
    "        print('计算VGGNet-16最后的全连接层的输出fc8的L2 loss')\n",
    "        objective = tf.nn.l2_loss(fc8)  # 计算VGGNet-16最后的全连接层的输出fc8的L2 loss\n",
    "        print('使用tf.gradients求相对于这个loss的所有模型参数的梯度')\n",
    "        grad = tf.gradients(objective, p)  # 使用tf.gradients求相对于这个loss的所有模型参数的梯度\n",
    "        print('求解梯度的操作grad')\n",
    "        time_tensorflow_run(sess, grad, {keep_prob: 0.5}, \"Forward-backward\")  # 这里的target为求解梯度的操作grad\n",
    "        print(\"运行完毕\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 256, 256)\n",
      "(50, 256, 256, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "***********************************************************\n",
      "run_benchmark中    image  <class 'torch.Tensor'>\n",
      "***********************************************************\n",
      "元素的类型： <class 'numpy.float32'>\n",
      "p 的类型<class 'list'>\n",
      "卷积层\n",
      "input_op的类型： <class 'torch.Tensor'>\n",
      "n_in的大小 ： 1\n",
      "conv1_1 Tensor(\"conv1_1:0\", shape=(50, 256, 256, 64), dtype=float32)\n",
      "卷积层\n",
      "input_op的类型： <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "n_in的大小 ： 64\n",
      "conv1_2 Tensor(\"conv1_2:0\", shape=(50, 256, 256, 64), dtype=float32)\n",
      "池化层\n",
      "pool1 Tensor(\"pool1:0\", shape=(50, 128, 128, 64), dtype=float32)\n",
      "卷积层\n",
      "input_op的类型： <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "n_in的大小 ： 64\n",
      "conv2_1 Tensor(\"conv2_1:0\", shape=(50, 128, 128, 128), dtype=float32)\n",
      "卷积层\n",
      "input_op的类型： <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "n_in的大小 ： 128\n",
      "conv2_2 Tensor(\"conv2_2:0\", shape=(50, 128, 128, 128), dtype=float32)\n",
      "池化层\n",
      "pool2 Tensor(\"pool2:0\", shape=(50, 64, 64, 128), dtype=float32)\n",
      "卷积层\n",
      "input_op的类型： <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "n_in的大小 ： 128\n",
      "conv3_1 Tensor(\"conv3_1:0\", shape=(50, 64, 64, 256), dtype=float32)\n",
      "卷积层\n",
      "input_op的类型： <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "n_in的大小 ： 256\n",
      "conv3_2 Tensor(\"conv3_2:0\", shape=(50, 64, 64, 256), dtype=float32)\n",
      "卷积层\n",
      "input_op的类型： <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "n_in的大小 ： 256\n",
      "conv3_3 Tensor(\"conv3_3:0\", shape=(50, 64, 64, 256), dtype=float32)\n",
      "池化层\n",
      "pool3 Tensor(\"pool3:0\", shape=(50, 32, 32, 256), dtype=float32)\n",
      "卷积层\n",
      "input_op的类型： <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "n_in的大小 ： 256\n",
      "conv4_1 Tensor(\"conv4_1:0\", shape=(50, 32, 32, 512), dtype=float32)\n",
      "卷积层\n",
      "input_op的类型： <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "n_in的大小 ： 512\n",
      "conv4_2 Tensor(\"conv4_2:0\", shape=(50, 32, 32, 512), dtype=float32)\n",
      "卷积层\n",
      "input_op的类型： <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "n_in的大小 ： 512\n",
      "conv4_3 Tensor(\"conv4_3:0\", shape=(50, 32, 32, 512), dtype=float32)\n",
      "池化层\n",
      "pool4 Tensor(\"pool4:0\", shape=(50, 16, 16, 512), dtype=float32)\n",
      "卷积层\n",
      "input_op的类型： <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "n_in的大小 ： 512\n",
      "conv5_1 Tensor(\"conv5_1:0\", shape=(50, 16, 16, 512), dtype=float32)\n",
      "卷积层\n",
      "input_op的类型： <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "n_in的大小 ： 512\n",
      "conv5_2 Tensor(\"conv5_2:0\", shape=(50, 16, 16, 512), dtype=float32)\n",
      "卷积层\n",
      "input_op的类型： <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "n_in的大小 ： 512\n",
      "conv5_3 Tensor(\"conv5_3:0\", shape=(50, 16, 16, 512), dtype=float32)\n",
      "池化层\n",
      "pool5 Tensor(\"pool5:0\", shape=(50, 8, 8, 512), dtype=float32)\n",
      "shp的shape: (50, 8, 8, 512)\n",
      "resh1的类型<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Tensor(\"resh1:0\", shape=(50, 32768), dtype=float32)\n",
      "fc6 的shape: Tensor(\"fc6:0\", shape=(50, 4096), dtype=float32)\n",
      "keep_prob 的shape： Tensor(\"Placeholder:0\", dtype=float32)\n",
      "...................................................\n",
      "变量所占内存大小 ： \n",
      "56\n",
      "56\n",
      "56\n",
      "360\n",
      "...................................................\n",
      "<class 'float'>   time:  9.200855731964111\n",
      "<class 'float'>   time:  1.5466787815093994\n",
      "<class 'float'>   time:  1.5845603942871094\n",
      "<class 'float'>   time:  1.5820071697235107\n",
      "<class 'float'>   time:  1.586763620376587\n",
      "<class 'float'>   time:  1.5829954147338867\n",
      "<class 'float'>   time:  1.5835189819335938\n",
      "<class 'float'>   time:  1.575026035308838\n",
      "<class 'float'>   time:  1.5837087631225586\n",
      "<class 'float'>   time:  1.5936973094940186\n",
      "<class 'float'>   time:  1.586106538772583\n",
      "2020-03-19 12:47:56.470068: step 0, duration = 1.586106538772583\n",
      "<class 'float'>   time:  1.5925090312957764\n",
      "<class 'float'>   time:  1.5836212635040283\n",
      "<class 'float'>   time:  1.5870225429534912\n",
      "<class 'float'>   time:  1.5817985534667969\n",
      "<class 'float'>   time:  1.5965142250061035\n",
      "<class 'float'>   time:  1.5832445621490479\n",
      "<class 'float'>   time:  1.5892739295959473\n",
      "<class 'float'>   time:  1.5854153633117676\n",
      "<class 'float'>   time:  1.5817837715148926\n",
      "<class 'float'>   time:  1.5863542556762695\n",
      "2020-03-19 12:48:12.339653: step 10, duration = 1.5863542556762695\n",
      "<class 'float'>   time:  1.5956416130065918\n",
      "<class 'float'>   time:  1.580333948135376\n",
      "<class 'float'>   time:  1.6023201942443848\n",
      "<class 'float'>   time:  1.5864195823669434\n",
      "<class 'float'>   time:  1.5952208042144775\n",
      "<class 'float'>   time:  1.5924501419067383\n",
      "<class 'float'>   time:  1.589689016342163\n",
      "<class 'float'>   time:  1.5897924900054932\n",
      "<class 'float'>   time:  1.591737985610962\n",
      "<class 'float'>   time:  1.5968573093414307\n",
      "2020-03-19 12:48:28.261113: step 20, duration = 1.5968573093414307\n",
      "<class 'float'>   time:  1.587158441543579\n",
      "<class 'float'>   time:  1.5858838558197021\n",
      "<class 'float'>   time:  1.6040668487548828\n",
      "<class 'float'>   time:  1.5892138481140137\n",
      "<class 'float'>   time:  1.5959436893463135\n",
      "<class 'float'>   time:  1.5976450443267822\n",
      "<class 'float'>   time:  1.5909652709960938\n",
      "<class 'float'>   time:  1.5933430194854736\n",
      "<class 'float'>   time:  1.5913949012756348\n",
      "<class 'float'>   time:  1.5959577560424805\n",
      "2020-03-19 12:48:44.192686: step 30, duration = 1.5959577560424805\n",
      "<class 'float'>   time:  1.5945675373077393\n",
      "<class 'float'>   time:  1.6011316776275635\n",
      "<class 'float'>   time:  1.6033689975738525\n",
      "<class 'float'>   time:  1.5868268013000488\n",
      "<class 'float'>   time:  1.606811761856079\n",
      "<class 'float'>   time:  1.5897586345672607\n",
      "<class 'float'>   time:  1.6023073196411133\n",
      "<class 'float'>   time:  1.5996313095092773\n",
      "<class 'float'>   time:  1.5974338054656982\n",
      "<class 'float'>   time:  1.5989978313446045\n",
      "2020-03-19 12:49:00.173522: step 40, duration = 1.5989978313446045\n",
      "<class 'float'>   time:  1.5921237468719482\n",
      "<class 'float'>   time:  1.6025338172912598\n",
      "<class 'float'>   time:  1.602189302444458\n",
      "<class 'float'>   time:  1.5991179943084717\n",
      "<class 'float'>   time:  1.5953459739685059\n",
      "<class 'float'>   time:  1.6007354259490967\n",
      "<class 'float'>   time:  1.6020832061767578\n",
      "<class 'float'>   time:  1.5983517169952393\n",
      "<class 'float'>   time:  1.6002748012542725\n",
      "<class 'float'>   time:  1.5951576232910156\n",
      "2020-03-19 12:49:16.161435: step 50, duration = 1.5951576232910156\n",
      "<class 'float'>   time:  1.5946500301361084\n",
      "<class 'float'>   time:  1.602466344833374\n",
      "<class 'float'>   time:  1.5979902744293213\n",
      "<class 'float'>   time:  1.6030943393707275\n",
      "<class 'float'>   time:  1.5980567932128906\n",
      "<class 'float'>   time:  1.6033780574798584\n",
      "<class 'float'>   time:  1.6034960746765137\n",
      "<class 'float'>   time:  1.595306634902954\n",
      "<class 'float'>   time:  1.607318639755249\n",
      "<class 'float'>   time:  1.6022956371307373\n",
      "2020-03-19 12:49:32.169488: step 60, duration = 1.6022956371307373\n",
      "<class 'float'>   time:  1.6052253246307373\n",
      "<class 'float'>   time:  1.6005990505218506\n",
      "<class 'float'>   time:  1.596545934677124\n",
      "<class 'float'>   time:  1.5994620323181152\n",
      "<class 'float'>   time:  1.6023035049438477\n",
      "<class 'float'>   time:  1.60103440284729\n",
      "<class 'float'>   time:  1.6057343482971191\n",
      "<class 'float'>   time:  1.603973150253296\n",
      "<class 'float'>   time:  1.598118782043457\n",
      "<class 'float'>   time:  1.6006813049316406\n",
      "2020-03-19 12:49:48.191104: step 70, duration = 1.6006813049316406\n",
      "<class 'float'>   time:  1.6008780002593994\n",
      "<class 'float'>   time:  1.5931124687194824\n",
      "<class 'float'>   time:  1.6111845970153809\n",
      "<class 'float'>   time:  1.5982961654663086\n",
      "<class 'float'>   time:  1.6000444889068604\n",
      "<class 'float'>   time:  1.6047697067260742\n",
      "<class 'float'>   time:  1.5976181030273438\n",
      "<class 'float'>   time:  1.6033961772918701\n",
      "<class 'float'>   time:  1.5983998775482178\n",
      "<class 'float'>   time:  1.5984272956848145\n",
      "2020-03-19 12:50:04.197231: step 80, duration = 1.5984272956848145\n",
      "<class 'float'>   time:  1.5968084335327148\n",
      "<class 'float'>   time:  1.5988707542419434\n",
      "<class 'float'>   time:  1.607154130935669\n",
      "<class 'float'>   time:  1.5960814952850342\n",
      "<class 'float'>   time:  1.5972802639007568\n",
      "<class 'float'>   time:  1.602698564529419\n",
      "<class 'float'>   time:  1.6030611991882324\n",
      "<class 'float'>   time:  1.5983669757843018\n",
      "<class 'float'>   time:  1.6015853881835938\n",
      "<class 'float'>   time:  1.605971097946167\n",
      "2020-03-19 12:50:20.205109: step 90, duration = 1.605971097946167\n",
      "<class 'float'>   time:  1.590406894683838\n",
      "<class 'float'>   time:  1.6068463325500488\n",
      "<class 'float'>   time:  1.5966167449951172\n",
      "<class 'float'>   time:  1.5928497314453125\n",
      "<class 'float'>   time:  1.6141297817230225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>   time:  1.5956075191497803\n",
      "<class 'float'>   time:  1.6020684242248535\n",
      "<class 'float'>   time:  1.6046409606933594\n",
      "<class 'float'>   time:  1.6138317584991455\n",
      "2020-03-19 12:50:34.622107: Forwardacross 100 steps, 1.5972716307640076 +/- 0.0069819818929841805sec / batch\n",
      "函数已大致运行完成///////////////////////////////////\n",
      "计算VGGNet-16最后的全连接层的输出fc8的L2 loss\n",
      "使用tf.gradients求相对于这个loss的所有模型参数的梯度\n",
      "求解梯度的操作grad\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[50,64,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: conv1_2/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1_1, conv1_2/w/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: gradients/fc8/BiasAdd_grad/BiasAddGrad/_71 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_584_gradients/fc8/BiasAdd_grad/BiasAddGrad\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'conv1_2/Conv2D', defined at:\n  File \"F:\\anaconda\\envs\\GP\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"F:\\anaconda\\envs\\GP\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2808, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-2a3b5aa95faa>\", line 3, in <module>\n    run_benchmark()\n  File \"<ipython-input-10-1576ee289805>\", line 25, in run_benchmark\n    predictions, softmax, fc8, p = inference_op(in_put, keep_prob)  # 构建网络结构获得参数列表\n  File \"<ipython-input-8-09150dc5db01>\", line 14, in inference_op\n    dw=1, p=p)\n  File \"<ipython-input-5-65ea27de7da6>\", line 15, in conv_op\n    conv = tf.nn.conv2d(input_op, kernel, (1, dh, dw, 1), padding='SAME')\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1042, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[50,64,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: conv1_2/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1_1, conv1_2/w/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: gradients/fc8/BiasAdd_grad/BiasAddGrad/_71 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_584_gradients/fc8/BiasAdd_grad/BiasAddGrad\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mF:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[50,64,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: conv1_2/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1_1, conv1_2/w/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: gradients/fc8/BiasAdd_grad/BiasAddGrad/_71 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_584_gradients/fc8/BiasAdd_grad/BiasAddGrad\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-2a3b5aa95faa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m16\u001b[0m  \u001b[1;31m# VGGNet-16模型的体积较大，如果使用较大的batch_size，GPU显存会不够用\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnum_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mrun_benchmark\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-1576ee289805>\u001b[0m in \u001b[0;36mrun_benchmark\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 使用tf.gradients求相对于这个loss的所有模型参数的梯度\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'求解梯度的操作grad'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mtime_tensorflow_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Forward-backward\"\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 这里的target为求解梯度的操作grad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-ed80ff71328a>\u001b[0m in \u001b[0;36mtime_tensorflow_run\u001b[1;34m(session, target, feed, info_string)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m# 每次迭代通过session.run执行\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 引入feed_dict方便后面传入keep_prob来控制Dropout层的保留比率\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mduration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mduration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"   time:  \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mduration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1289\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1291\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1293\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[50,64,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: conv1_2/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1_1, conv1_2/w/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: gradients/fc8/BiasAdd_grad/BiasAddGrad/_71 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_584_gradients/fc8/BiasAdd_grad/BiasAddGrad\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'conv1_2/Conv2D', defined at:\n  File \"F:\\anaconda\\envs\\GP\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"F:\\anaconda\\envs\\GP\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2808, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-2a3b5aa95faa>\", line 3, in <module>\n    run_benchmark()\n  File \"<ipython-input-10-1576ee289805>\", line 25, in run_benchmark\n    predictions, softmax, fc8, p = inference_op(in_put, keep_prob)  # 构建网络结构获得参数列表\n  File \"<ipython-input-8-09150dc5db01>\", line 14, in inference_op\n    dw=1, p=p)\n  File \"<ipython-input-5-65ea27de7da6>\", line 15, in conv_op\n    conv = tf.nn.conv2d(input_op, kernel, (1, dh, dw, 1), padding='SAME')\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1042, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[50,64,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: conv1_2/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1_1, conv1_2/w/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: gradients/fc8/BiasAdd_grad/BiasAddGrad/_71 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_584_gradients/fc8/BiasAdd_grad/BiasAddGrad\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16  # VGGNet-16模型的体积较大，如果使用较大的batch_size，GPU显存会不够用\n",
    "num_batches = 100\n",
    "run_benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
