{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import re\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'E:\\\\GPImage\\\\HandleImage\\\\model\\\\'\n",
    "\n",
    "testPath = 'E:\\\\GPImage\\\\HandleImage\\\\EnhanceImage\\\\'\n",
    "\n",
    "savePath = 'E:\\\\GPImage\\\\HandleImage\\\\HandleEnhanceImage\\\\'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileList = os.listdir(testPath)\n",
    "totalNum = len(fileList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2283, 65536)\n",
      "(2283,)\n"
     ]
    }
   ],
   "source": [
    "#  加载数据   \n",
    "class Data:\n",
    "    def __init__(self, filenames, need_shuffle):\n",
    "        all_data = []\n",
    "        all_labels = []\n",
    "        \n",
    "        for i in range(totalNum):\n",
    "            \n",
    "            iPath = testPath + str(fileList[i])\n",
    "            \n",
    "            #  添加 文件标签\n",
    "            # 获取文件名\n",
    "            y = fileList[i]\n",
    "            # 去除文件后缀\n",
    "            y = os.path.splitext(y)\n",
    "            y_ = y[0]\n",
    "            # 去除文件中的数字，获取文件标签\n",
    "            y_ = \"\".join(filter(str.isalpha, y_))\n",
    "            if(y_ == 'eye'):\n",
    "                y_label = 1\n",
    "            elif(y_ == 'back'):\n",
    "                y_label = 2\n",
    "            elif(y_ == 'face'):\n",
    "                y_label = 3\n",
    "            elif(y_ == 'left'):\n",
    "                y_label = 4\n",
    "            else:\n",
    "                y_label = 5\n",
    "            #   添加文件图片数据 \n",
    "            src = cv.imread(iPath)\n",
    "            image = cv.cvtColor(src, cv.COLOR_BGR2GRAY)\n",
    "            image = image.flatten()\n",
    "            \n",
    "            all_data.append(image)\n",
    "            all_labels.append(y_label)\n",
    "            \n",
    "            \n",
    "        self._data = np.vstack(all_data)\n",
    "        # 将数据缩放到[-1, 1]\n",
    "        self._data = self._data / 127.5 - 1\n",
    "        self._labels = np.hstack(all_labels)\n",
    "        \n",
    "        print(self._data.shape)\n",
    "        print(self._labels.shape)\n",
    "        \n",
    "        self._num_examples = self._data.shape[0]\n",
    "        self._need_shuffle = need_shuffle\n",
    "        \n",
    "        self._indicator = 0  # 当前遍历到的位置\n",
    "#         if self._need_shuffle:\n",
    "#             self._shuffle_data()\n",
    "        \n",
    "        \n",
    "#     \"\"\"打乱训练数据集\"\"\"\n",
    "#     def _shuffle_data(self):\n",
    "#         p = np.random.permutation(self._num_examples)\n",
    "#         self._data = self._data[p]\n",
    "#         self._labels = self._labels[p]\n",
    "        \n",
    "    \"\"\"返回batch_size个样本\"\"\"\n",
    "    def next_batch (self, batch_size):\n",
    "        end_indicator = self._indicator + batch_size\n",
    "        if end_indicator > self._num_examples:\n",
    "            if self._need_shuffle:\n",
    "                self._shuffle_data()\n",
    "                self._indicator = 0\n",
    "                end_indicator = batch_size\n",
    "            else:\n",
    "                raise Exception(\"have no more examples\")\n",
    "        if end_indicator > self._num_examples:\n",
    "            raise Exception(\"batch_size is larger than all examples\")\n",
    "        batch_data = self._data[self._indicator: end_indicator]\n",
    "        batch_labels = self._labels[self._indicator: end_indicator]\n",
    "        self._indicator = end_indicator\n",
    "        return batch_data, batch_labels\n",
    "\n",
    "test_filenames = [os.path.join(testPath)]\n",
    "test_data = Data(test_filenames, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from E:\\GPImage\\HandleImage\\model\\iris_model.ckpt-700\n",
      "输入数据获取完毕\n",
      "-----------------------\n",
      "运算开始\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[2283,32,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: conv1_1/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Reshape, conv1_1/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: output/_91 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_91_output\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'conv1_1/Conv2D', defined at:\n  File \"F:\\anaconda\\envs\\GP\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"F:\\anaconda\\envs\\GP\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-3ccf363d6e66>\", line 11, in <module>\n    new_saver = tf.train.import_meta_graph('E://GPImage//HandleImage//model/iris_model.ckpt-700.meta')\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1939, in import_meta_graph\n    **kwargs)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\framework\\meta_graph.py\", line 744, in import_scoped_meta_graph\n    producer_op_list=producer_op_list)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\", line 442, in import_graph_def\n    _ProcessNewOps(graph)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\", line 234, in _ProcessNewOps\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3289, in _add_new_tf_operations\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3289, in <listcomp>\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3180, in _create_op_from_tf_operation\n    ret = Operation(c_op, self)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[2283,32,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: conv1_1/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Reshape, conv1_1/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: output/_91 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_91_output\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mF:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[2283,32,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: conv1_1/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Reshape, conv1_1/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: output/_91 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_91_output\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-3ccf363d6e66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m         classification_result = sess.run(\n\u001b[0;32m     23\u001b[0m                                      \u001b[0mfetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m                                      \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m                                         )\n\u001b[0;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-----------------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1289\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1291\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1293\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[2283,32,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: conv1_1/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Reshape, conv1_1/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: output/_91 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_91_output\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'conv1_1/Conv2D', defined at:\n  File \"F:\\anaconda\\envs\\GP\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"F:\\anaconda\\envs\\GP\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-3ccf363d6e66>\", line 11, in <module>\n    new_saver = tf.train.import_meta_graph('E://GPImage//HandleImage//model/iris_model.ckpt-700.meta')\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1939, in import_meta_graph\n    **kwargs)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\framework\\meta_graph.py\", line 744, in import_scoped_meta_graph\n    producer_op_list=producer_op_list)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\", line 442, in import_graph_def\n    _ProcessNewOps(graph)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\", line 234, in _ProcessNewOps\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3289, in _add_new_tf_operations\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3289, in <listcomp>\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3180, in _create_op_from_tf_operation\n    ret = Operation(c_op, self)\n  File \"F:\\anaconda\\envs\\GP\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[2283,32,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: conv1_1/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Reshape, conv1_1/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: output/_91 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_91_output\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "# 初始化函数\n",
    "init = tf.global_variables_initializer() \n",
    "batch_size = 2283\n",
    "batch_steps = 750\n",
    "\n",
    "images_data = test_data\n",
    "\n",
    "#实例化session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    new_saver = tf.train.import_meta_graph('E://GPImage//HandleImage//model/iris_model.ckpt-700.meta')\n",
    "    new_saver.restore(sess, tf.train.latest_checkpoint('E://GPImage//HandleImage//model/'))\n",
    "    for i in range(batch_steps):\n",
    "        batch_data, batch_labels = test_data.next_batch(batch_size)\n",
    "        graph = tf.get_default_graph()\n",
    "        logits = graph.get_tensor_by_name(\"output:0\")\n",
    "        x = graph.get_tensor_by_name(\"x_input:0\")\n",
    "        print(\"输入数据获取完毕\")\n",
    "        print(\"-----------------------\")    \n",
    "        print(\"运算开始\")\n",
    "    \n",
    "        classification_result = sess.run(\n",
    "                                     fetches = logits,\n",
    "                                     feed_dict={x: batch_data}\n",
    "                                        )\n",
    "        print(\"-----------------------\")\n",
    "        print(\"运算结束，输出预测\")\n",
    "        #打印出预测矩阵\n",
    "        print(classification_result)\n",
    "        #根据索引通过字典对应分类\n",
    "    \n",
    "        output = classification_result\n",
    "        print(\"保存图片\")\n",
    "        for i in range(len(output)):\n",
    "            if output[i]== 1:\n",
    "                path = savePath + 'BACK\\\\'\n",
    "                name = path + str(i) + '_up.png'           \n",
    "            elif output[i] == 2:\n",
    "                path = savePath + 'EYE\\\\'\n",
    "                name = path + str(i) + '_eye.png'     \n",
    "            elif output[i] == 3:\n",
    "                path = savePath + 'FACE\\\\'\n",
    "                name = path + str(i) + '_back.png'     \n",
    "            elif output[i] == 4:\n",
    "                path = savePath + 'LEFT\\\\'\n",
    "                name = path + str(i) + '_left.png'\n",
    "            else:\n",
    "                path = savePath + 'UP\\\\'\n",
    "                name = path + str(i) + '_face.png'\n",
    "            \n",
    "            iPath = testPath + str(fileList[i])\n",
    "            src = cv.imread(iPath)\n",
    "            image_i = cv.cvtColor(src, cv.COLOR_BGR2GRAY)\n",
    "#             cv.imwrite(name, image_i) \n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 读取分类图片\n",
    "# def get_image(path):\n",
    "#     imgs = []\n",
    "    \n",
    "#     fileList = os.listdir(path)\n",
    "#     totalNum = len(fileList)\n",
    "    \n",
    "#     for i in range(0, totalNum):\n",
    "#         iPath = path + str(fileList[i])\n",
    "#         #   添加文件图片数据 \n",
    "#         src = cv.imread(iPath)\n",
    "#         image = cv.cvtColor(src, cv.COLOR_BGR2GRAY)\n",
    "#         imgs.append(image)\n",
    "#     return np.asarray(imgs, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # 测试图片\n",
    "# def evaluate_image(image_array):\n",
    "#     with tf.Graph().as_default():\n",
    "#         Batch_size = 1\n",
    "#         N_classes = 4\n",
    "        \n",
    "#         image = tf.cast(image_array, tf.float32)\n",
    "#         image = tf.image.per_image_standardization(image)\n",
    "#         image = tf.reshape(image, [1, 256, 256, 1])\n",
    "        \n",
    "#         logs_train_dir = 'E:/GPImage/HandleImage/model/iris_model.ckpt.meta'\n",
    " \n",
    "#         saver = tf.train.Saver()\n",
    " \n",
    "#         with tf.Session() as sess:\n",
    " \n",
    "#             print(\"Reading checkpoints...\")\n",
    "#             ckpt = tf.train.get_checkpoint_state(logs_train_dir)\n",
    "#             if ckpt and ckpt.model_checkpoint_path:\n",
    "#                 global_step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]\n",
    "#                 saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "#                 print('Loading success, global_step is %s' % global_step)\n",
    "#             else:\n",
    "#                 print('No checkpoint file found')\n",
    " \n",
    "#             prediction = sess.run(logit, feed_dict={x: image_array})\n",
    "#             max_index = np.argmax(prediction)\n",
    "#             print(max_index)\n",
    "#             if max_index == 0:\n",
    "#                 print('这是玫瑰花的可能性为： %.6f' % prediction[:, 0])\n",
    "#             elif max_index == 1:\n",
    "#                 print('这是郁金香的可能性为： %.6f' % prediction[:, 1])\n",
    "#             elif max_index == 2:\n",
    "#                 print('这是蒲公英的可能性为： %.6f' % prediction[:, 2])\n",
    "#             else:\n",
    "#                  print('这是这是向日葵的可能性为： %.6f' % prediction[:, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# images_dict = {0:'back',1:'eye',2:'face',3:'left',4:'up'}\n",
    "# \"\"\"加载数据\"\"\"  \n",
    "\n",
    "# #     # 读取图片数据并转矩阵\n",
    "# #     images = get_image(testPath)\n",
    "# #     print(str(images.shape))\n",
    "# #     images = images.astype(float)\n",
    "# #     x_image = np.reshape(images, [-1,65536])\n",
    "\n",
    "# # 加载模型\n",
    "# with tf.Session() as sess:\n",
    "#     new_saver = tf.train.import_meta_graph('E://GPImage//HandleImage//model/iris_model.ckpt-700.meta')\n",
    "#     new_saver.restore(sess, tf.train.latest_checkpoint('E://GPImage//HandleImage//model/'))\n",
    "\n",
    "#     print(\"-----------------------\")\n",
    "#     print(\"获取输入的参数\")\n",
    "#     graph = tf.get_default_graph()\n",
    "#     x = graph.get_tensor_by_name(\"x_input:0\")\n",
    "#     y = graph.get_tensor_by_name(\"y_input:0\")\n",
    "#     logits = graph.get_tensor_by_name(\"output:0\")\n",
    "#     print(\"输入数据获取完毕\")\n",
    "#     print(\"-----------------------\")    \n",
    "#     print(\"运算开始\")\n",
    "    \n",
    "#     classification_result = sess.run(\n",
    "#                                      fetches = logits,\n",
    "#                                      feed_dict = {x: image}\n",
    "#                                     )\n",
    "    \n",
    "#     print(\"-----------------------\")\n",
    "#     print(\"运算结束，输出预测\")\n",
    "#     #打印出预测矩阵\n",
    "#     print(classification_result)\n",
    "#     #打印出预测矩阵每一行最大值的索引\n",
    "#     print(tf.argmax(classification_result,1).eval())\n",
    "#     #根据索引通过字典对应分类\n",
    "    \n",
    "#     output = []\n",
    "#     output = tf.argmax(classification_result,1).eval()\n",
    "    \n",
    "#     for i in range(len(output)):\n",
    "#         print(\"第\",i+1,\"张图片的预测为:\"+ images_dict[output[i]])\n",
    "        \n",
    "\n",
    "# #     # 模型数据输出\n",
    "# #     # 查看模型中的trainable variables\n",
    "# #     tvs = [v for v in tf.trainable_variables()]\n",
    "# #     for v in tvs:\n",
    "# #         print(v.name)\n",
    "# #         print(sess.run(v))\n",
    "# #     # 查看模型中的所有tensor或者operations\n",
    "# #     gv = [v for v in tf.global_variables()]\n",
    "# #     for v in gv:\n",
    "# #         print(v.name)\n",
    "# #     # 获得几乎所有的operations相关的tensor\n",
    "# #     ops = [o for o in sess.graph.get_operations()]\n",
    "# #     for o in ops:\n",
    "# #         print(o.name)\n",
    "# #     print(\"模型加载成功： \" + str(sess.run()))        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
